- name: Datanode using ansible
  gather_facts: No
  remote_user: apache
  become: true
  become_method: sudo
  hosts: "{{ Host }}"
  vars_prompt:
  - name: Host
    prompt: "Enter Host ip"
    private: no

  - name: d_dir
    prompt: "Enter datanode directory name you want to create"
    private: no

  - name: n_ip
    prompt: "Enter namenode ip eg 1.2.3.4"
    private: no

  - name: hadoop_port
    prompt: "Enter hadoop port"
    private: no

  tasks:
  - name: copying hadoop software
    copy:
     src: "/root/Desktop/hadoop-1.2.1-1.x86_64.rpm"
     dest: "/root/soft/"

  - name: copying java software
    copy:
     src: "/root/Desktop/jdk-8u171-linux-x64.rpm"
     dest: "/root/soft"

  - name: checking whether java package is already installed of not
    shell: "java -version"
    register: java_ver
    ignore_errors: yes

  - name: checking whether hadoop package is already installed of not
    shell: "hadoop -version"
    register: hadoop_ver
    ignore_errors: yes

  - name: java -version output
    debug:
      var: java_ver

  - name: hadoop -version output
    debug:
      var: hadoop_ver

  - name: installing java packages
    shell: "rpm -i /root/soft/jdk-8u171-linux-x64.rpm"
    register: java_installed
    when: java_ver.rc == 127

  - name: java success code
    debug:
     var: java_installed.stdout

  - name: installing hadoop packages
    shell: "rpm -i /root/soft/hadoop-1.2.1-1.x86_64.rpm --force"
    register: hadoop_installed
    when: hadoop_ver.rc == 127

  - name: hadoop success code
    debug:
     var: hadoop_installed.stderr_lines

  - name: creating datanode directory
    file:
     path: "{{ d_dir }}"
     state: directory

  - name: copying hdfs-site file
    template:
     src: "ahdfs-site.xml"
     dest: "/etc/hadoop/hdfs-site.xml"

  - name: copying core-site file
    template:
     src: "acore-site.xml"
     dest: "/etc/hadoop/core-site.xml"

  - name: starting service
    shell: "hadoop-daemon.sh start datanode"
    register: service

  - name: success code
    shell: "jps"
    register: success

  - debug:
     var: success.stdout_lines

  - name: dfsadmin report
    shell: "hadoop dfsadmin -report"
    register: report

  - name: report
    debug:
     var: report.stdout_lines

